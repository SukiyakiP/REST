{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  DataLoader, TensorDataset,Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "from RESTCORE import REST\n",
    "from RESTutils import create_sequences,get_oversampled_indices, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets the parameters for the REST model and training process, change as needed, make sure to set the paths to your dataset and model correctly.\n",
    "fs = 512  # Sampling frequency\n",
    "epoch_length = 4  # Epoch length in seconds\n",
    "window_size = 90 # Window size for sliding window\n",
    "step = 60 # Step size for sliding window\n",
    "nperseg = 256  # Segment length for PSD computation\n",
    "batch_size = 128 # Batch size for training\n",
    "n_epochs = 100  # Number of training epochs\n",
    "f_bin=130 # Frequency bin for PSD computation\n",
    "n_classes = 3   # Number of sleep stages (e.g., Wake, NREM, REM)\n",
    "WeightedLoss = True # Use weighted loss function\n",
    "OversampleRAM = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = REST(\n",
    "    in_feat=f_bin,\n",
    "    n_classes=3,\n",
    "    win_len=window_size,\n",
    "    d_model=256,\n",
    "    nhead=8,\n",
    "    nlayers_epoch=4,\n",
    "    nlayers_seq=4,\n",
    "    ff=512,\n",
    "    fc_hidden1=128,\n",
    "    fc_hidden2=64,\n",
    "    dropout=0.1\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for a npz and pth files from the script directory. npz is the training dataset, pth is the model file, \n",
    "script_dir = os.getcwd()\n",
    "# Look for a .npz file\n",
    "npz_files = glob.glob(os.path.join(script_dir, \"*.npz\"))\n",
    "if not npz_files:\n",
    "    raise FileNotFoundError(\"No .npz training dataset found in the script directory.\")\n",
    "elif len(npz_files) > 1:\n",
    "    print(\"Multiple .npz files found, using the first one.\")\n",
    "\n",
    "ds_path = npz_files[0]\n",
    "print(f\"Using dataset: {ds_path}\")\n",
    "\n",
    "Model_path = os.path.join(script_dir, \"model_general.pth\")\n",
    "print(f\"Model will be saved to: {Model_path}\")\n",
    "\n",
    "# use following two variables to set your own paths if needed\n",
    "# ds_path = r\"\" # insert path to your dataset here\n",
    "# Model_path=r\"\" # insert path to save the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr = np.load(ds_path)\n",
    "EEG = arr[\"EEG\"]     # shape: [n_epochs,   256 * 4]  (down‑sampled to 64 Hz)\n",
    "EMG = arr[\"EMG\"]     # shape: [n_epochs, 1024 * 4]  (down‑sampled to 256 Hz)\n",
    "score = arr[\"score\"]\n",
    "score=score-1 # convert to 0,1,2,3 (wake=0,NREM=1,REM=2, Artefact=3)\n",
    "score[score >= 3] = -100 # set Artefact to -100 (ignore in loss function)\n",
    "score[score < 0] = -100 # set Artefact to -100 (ignore in loss function)\n",
    "score = score.astype(np.int64) \n",
    "del arr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_power = np.mean(EEG ** 2, axis=(1, 2))  # EEG power in each epoch\n",
    "eeg_thresh = np.percentile(eeg_power, 99) # threshold for suspect epochs\n",
    "suspect_epochs = np.where((eeg_power > eeg_thresh))[0] #exclude epoch with super high EEG power\n",
    "score[suspect_epochs] = -100 # mark suspect epochs as invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals, counts = np.unique(score, return_counts=True)\n",
    "for val, count in zip(unique_vals, counts):\n",
    "    print(f\"Label {val}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along feature dimension  → [n_epochs, frames=5, feat=65*2]\n",
    "epoch_tensor = np.concatenate([EEG, EMG], axis=-1).astype(np.float32)\n",
    "labels = score # [n_epochs]\n",
    "\n",
    "# Build sliding windows exactly like before\n",
    "X, Y = create_sequences(window_size, step,epoch_tensor, labels)\n",
    "del EEG, EMG ,epoch_tensor\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "del X, Y\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "oversampled_idx = get_oversampled_indices(Y_train.numpy(), repeat_factor=3)\n",
    "\n",
    "if OversampleRAM:\n",
    "    train_dataset = Subset(train_dataset, oversampled_idx)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # still shuffle across the repeated indices\n",
    "    )\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_flat = Y_train.view(-1).cpu().numpy()\n",
    "del X_train, X_val, Y_train, Y_val\n",
    "train_labels_flat = train_labels_flat[train_labels_flat != -100]  # Fix: remove -100 before computing weights\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_flat), y=train_labels_flat)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "\n",
    "if WeightedLoss:\n",
    "    # criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=2, ignore_index=-100)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "patientce = 0\n",
    "counter = 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_X, batch_Y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs} - Training\"):\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)  # Shape: [batch_size, sequence_length, n_classes]\n",
    "        loss = criterion(output.view(-1, n_classes), batch_Y.view(-1))  # Flatten for loss computation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{n_epochs} - Validation\"):\n",
    "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "            output = model(batch_X)  # Shape: [batch_size, sequence_length, n_classes]\n",
    "            loss = criterion(output.view(-1, n_classes), batch_Y.view(-1))  # Flatten for loss computation\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output.data, 2)  # Shape: [batch_size, sequence_length] \n",
    "            total += batch_Y.size(0) * batch_Y.size(1)  # Total number of predictions\n",
    "            correct += (predicted == batch_Y).sum().item()  # Correct predictions\n",
    "\n",
    "    # Print epoch results\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), Model_path)\n",
    "        print(f\"New best model saved with accuracy {best_val_accuracy:.2f}%\")\n",
    "    else:\n",
    "        patientce += 1\n",
    "        if patientce >= 50:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "print(f\"Training complete. Best validation accuracy: {best_val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(Model_path,weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "# Store all predictions and targets\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in val_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        output = model(batch_X)  # Shape: [B, W, C]\n",
    "        preds = torch.argmax(output, dim=2)  # [B, W]\n",
    "\n",
    "        all_preds.append(preds.cpu().view(-1))\n",
    "        all_targets.append(batch_Y.view(-1))  # Already on CPU\n",
    "\n",
    "# Concatenate all batches\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "# Filter out ignored labels (e.g., -100)\n",
    "mask = all_targets != -100\n",
    "all_preds = all_preds[mask]\n",
    "all_targets = all_targets[mask]\n",
    "\n",
    "# Print results\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(classification_report(all_targets, all_preds, target_names=[\"Wake\", \"NREM\", \"REM\"]))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_targets, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
